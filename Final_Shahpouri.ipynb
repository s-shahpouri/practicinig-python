{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the relationship between stress levels and physical activity in participants?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name:\n",
    "    Samaneh Shahpouri\n",
    "### Student number:\n",
    "    460145"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "The relationship between stress levels and physical activity has been widely studied, with a significant body of evidence suggesting that physical activity can help to prevent, as well as improve, general physical and mental well-being in the context of stress. However, the specific relationship between stress levels and physical activity in different geographical regions is not well understood. The objective of the current study is to examine the relationship between stress levels and physical activity in participants from different geographical regions within the Lifelines cohort.\n",
    "\n",
    "This study will make use of data from the Lifelines cohort, a large-scale population-based study that has been collecting data on the health and well-being of individuals living in the northern Netherlands since 2006. By examining the relationship between stress levels and physical activity in participants from different geographical regions within the Lifelines cohort, this study aims to provide a more nuanced understanding of the relationship between these two factors and how it may vary across different populations. The results of this study will be of great importance for public health and well-being, as they will inform the development of effective interventions aimed at reducing the negative effects of stress and promoting physical activity.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the data\n",
    "\n",
    "\n",
    "\n",
    "## **Stress**\n",
    "\n",
    "Data on past-year stress exposure (section: mental health) at baseline and follow-up (3 time points: follow-up questionnaire 1 and 2 and questionnaire at second assessment).\n",
    "Two stress exposure questionnaires were administered: the List of Threatening Experiences (LTE) measuring acute stressful life events (or SLE), and the Long-term Difficulties Inventory\n",
    "(LDI) measuring long-term difficulties (LTD) i.e. more chronic stressors. The questionnaires were part of the questionnaire packs to be administered at home. Both concern stressors in the past year. The validation and the reliability of the LDI was performed in a study by Rosmalen et al.\n",
    "The LTE lists 12 stressful life events (e.g. death of a relative, serious disease) and asks whether participants experienced such an event in the past year (no=2, yes=1). Items 13 (“did you\n",
    "experience any other major life events in the past year?”) and 13A (“can you briefly describe this event?”) are discarded.\n",
    "The LDI lists 12 potential sources of chronic stress (e.g. financial difficulties, work-related stress, strained relationships) and asks how much the participant was affected by this type of stress (not=1, somewhat=2, much=3). Variable Label\n",
    "\n",
    "**LTE_SUM_T1** Total number of stressful life events that happened to participant in the past year at baseline as mean (T1)\n",
    "\n",
    "**LDI_SUM_T1** Total amount of stress from long-term/chronic stressors experienced by the participant at baseline as mean (T1)\n",
    "\n",
    "**LTE_SUM_T2** Total number of stressful life events that happened to participant in the past year at second assessment as mean (T2)\n",
    "\n",
    "**LDI_SUM_T2** Total amount of stress from long-term/chronic stressors experienced by the participant at second assessment as mean (T2)\n",
    "\n",
    "    Since we are not studying temporal changes in this study, we will not be using T2 data, which may be useful for further research."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Physical Activity**\n",
    "\n",
    "\n",
    "Based on the raw data from the SQUASH instrument in 1A Questionnaire 2, the sum scores for\n",
    "physical activity per activity type and overall were calculated for all adult participants who\n",
    "sufficiently filled in the questionnaire (sections: lifestyle & environment and secondary & linked\n",
    "variables).\n",
    "\n",
    "\n",
    "**MWK_VAL** Minutes of weekly physical activity on moderate and vigorous intensity level\n",
    "at baseline as mean (T1)\n",
    "\n",
    "**SCOR_VAL** Score for weekly physical activity on moderate and vigorous intensity level,\n",
    "based on the sum of minutes per activity times the intensity of the specific\n",
    "activity at baseline as mean (T1)\n",
    "\n",
    "**MWK_NO_VAL** Minutes of weekly physical activity on moderate and vigorous intensity level,\n",
    "in leisure time and commuting domains (but not occupational) at baseline as\n",
    "mean (T1\n",
    "\n",
    "**SCOR_NO_VAL** Score for weekly physical activity on moderate and vigorous intensity level,\n",
    "in leisure time and commuting domains (but not occupational), based on the\n",
    "sum of minutes per activity times the intensity of the specific activity at\n",
    "baseline as mean (T1)\n",
    "\n",
    "**SPORTS_T1**  Minutes of weekly excercise as sport (T1).\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, our intention was to only investigate the correlation between physical activity and stress levels. However, after conducting further analysis of the data, we realized that body mass index (BMI) was also a significant factor affecting physical activity. Therefore, we have decided to include BMI as a personal characteristic in our study for further investigation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for data processing and visualization\n",
    "import pandas as pd # collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "import numpy as np  # foundational package for scientific computing\n",
    "import re           # Regular expression operations\n",
    "import matplotlib.pyplot as plt # Collection of functions for scientific and publication-ready visualization\n",
    "\n",
    "\n",
    "# Importing Plotly libraries for interactive and dynamic visualizations\n",
    "import plotly.offline as py     # Open source library for composing, editing, and sharing interactive data visualization \n",
    "from matplotlib import pyplot as pp\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# Importing Seaborn library for statistical visualizations\n",
    "import seaborn as sns  # Visualization library based on matplotlib, provides interface for drawing attractive statistical graphics\n",
    "\n",
    "# Importing yaml library for processing yaml files\n",
    "import yaml\n",
    "\n",
    "# Suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # collection of functions for data processing\n",
    "import numpy as np  # foundational package for scientific computing\n",
    "import matplotlib.pyplot as plt # Collection of functions for visualization\n",
    "import seaborn as sns  # Visualization library based on matplotlib\n",
    "import yaml # Importing yaml library for processing yaml files\n",
    "\n",
    "    \n",
    "import numpy as np\n",
    "from scipy.stats import iqr # iqr is the Interquartile Range function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "with open(\"config.yml\", \"r\") as reader:\n",
    "    config = yaml.safe_load(reader)\n",
    "\n",
    "# Load data from the configuration\n",
    "file = config['path']\n",
    "df_zipcode = pd.read_csv(file, delimiter='\\t', encoding='utf-16le')\n",
    "\n",
    "file = config['path_general']\n",
    "df_zipcode_general= pd.read_csv(file, delimiter='\\t', encoding='utf-16le')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select appropriate columns from the dataframe.\n",
    "new_general = df_zipcode_general[['ZIPCODE', 'MWK_VAL', 'SCOR_VAL',\n",
    "                                  'MWK_NO_VAL', 'SCOR_NO_VAL', 'SPORTS_T1',\n",
    "                                  'LTE_SUM_T1', 'LDI_SUM_T1']]\n",
    "\n",
    "# Select appropriate columns from the dataframe.\n",
    "new_zip = df_zipcode[['ZIPCODE', 'GENDER', 'AGE_T1',\n",
    "             'MWK_VAL', 'SCOR_VAL', 'MWK_NO_VAL', 'SCOR_NO_VAL', \n",
    "             'SPORTS_T1','LTE_SUM_T1', 'LDI_SUM_T1', 'BMI_T1']]\n",
    "\n",
    "# Change to desire format.\n",
    "new_zip.iloc[:, 2:] = new_zip.iloc[:, 2:].apply(lambda x: x.str.replace(',', '.')).astype(float)\n",
    "\n",
    "# Merge for obtaining zipcodes.\n",
    "new_df = new_general.merge(new_zip,on= 'ZIPCODE', how = 'inner')\n",
    "\n",
    "# Remove duplicate columns.\n",
    "new_df = new_df.drop(new_df.columns[new_df.columns.str.contains('_x')], axis=1)\n",
    "\n",
    "# Remove \"_y\" from header names\n",
    "new_df.rename(columns={col: col.rstrip('_y') for col in new_df.columns}, inplace=True)\n",
    "\n",
    "\n",
    "gender = new_df['GENDER']\n",
    "cond_list = [gender==1, gender==2]\n",
    "choice_list = [\"Male\", \"Female\"]\n",
    "\n",
    "new_df['GENDER'] = np.select(cond_list, choice_list)\n",
    "new_df['GENDER'] = new_df['GENDER'].astype(\"category\")\n",
    "df = new_df\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about data set\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing value. Time for further investigation about data.\n",
    "\n",
    "\n",
    "-------------------------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Summary\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()\n",
    "exclude = ['ZIPCODE', 'GENDER', 'AGE_T1']\n",
    "num_plots = len([c for c in columns if c not in exclude])\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, column in enumerate([c for c in columns if c not in exclude]):\n",
    "    y = df[column]\n",
    "    axs[i].hist(y, density=True, color='mistyrose')\n",
    "    mean = y.mean()\n",
    "    axs[i].axvline(mean, color='r', linestyle='dashed', linewidth=1)\n",
    "    robust = y.median()\n",
    "    axs[i].axvline(robust, color='b', linestyle='dashed', linewidth=1)\n",
    "    x = np.linspace(y.min()-1, y.max(), 1000)\n",
    "    mu, std = norm.fit(y)\n",
    "    yr = norm.pdf(x, mu, std)\n",
    "    axs[i].plot(x, yr, 'silver', linewidth=2)\n",
    "    axs[i].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive(df):\n",
    "    desc = df.drop(['GENDER', 'ZIPCODE', 'AGE_T1'],\n",
    "     axis=1).describe().round(1).drop(['count', 'std', '50%'], axis=0)\n",
    "    i = -0.1\n",
    "    j = 0\n",
    "    Row = int(round(len(desc.columns.tolist())/2 + 0.1))\n",
    "    f, ax = plt.subplots(Row, 2, figsize=(30, 15))\n",
    "    colors = ['turquoise', 'tomato', 'limegreen','purple' , 'gold', 'sandybrown', 'orchid', 'dodgerblue']\n",
    "    c = 0\n",
    "    for name in desc.columns.tolist():\n",
    "        desc[name].plot(kind='barh', figsize=(8, 7), title=name, ax=ax[round(i), j], fontsize=8, color=colors[c%len(colors)])\n",
    "        for k, v in enumerate(desc[name].tolist()):\n",
    "            ax[round(i), j].text(v, k-0.1, str(v), color='black', size=8)\n",
    "            ax[round(i), j].title.set_size(8) # set font size for title\n",
    "\n",
    "        i += 0.5\n",
    "        if j == 0:\n",
    "            j = 1\n",
    "        else:\n",
    "            j = 0\n",
    "        c += 1\n",
    "    f.tight_layout()\n",
    "\n",
    "descriptive(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Q plot\n",
    "A Q-Q (quantile-quantile) plot is a graphical tool used to compare two probability distributions by plotting their quantiles against each other. By creating this Q-Q plot, we can quickly and easily assess whether the data is approximately normally distributed and compare the distribution of samples to the normal distribution. It also allows us to visualize the 95% confidence interval of the sample data.\n",
    "\n",
    "If the data points align closely with the normal line, it suggests that the data is approximately normally distributed. If the data points deviate significantly from the line, it suggests that the data is not normally distributed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DS_Q_Q_Plot(y, est = 'robust', column = '',ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "      Estimated mu, sigma, n, and expected number of datapoints\n",
    "      outside CI in Q-Q-plot.\n",
    "    Author:            M.E.F. Apol\n",
    "    \"\"\"\n",
    "\n",
    "    mu_0 = kwargs.get('mu', None)\n",
    "    sigma_0 = kwargs.get('sigma', None)\n",
    "    \n",
    "    n = len(y); y_os = np.sort(y)\n",
    "    mu_ML = np.mean(y); sigma2_ML = np.var(y); sigma_ML = np.std(y) \n",
    "    s2 = np.var(y, ddof=1); s = np.std(y, ddof=1); mu_R = np.median(y)\n",
    "    sigma_R = iqr(y)/1.349\n",
    "\n",
    "    # Assign values of mu and sigma for z-transform:\n",
    "    if est == 'ML':\n",
    "        mu, sigma = mu_ML, s\n",
    "    elif est == 'robust':\n",
    "        mu, sigma = mu_R, sigma_R\n",
    "    elif est == 'preset':\n",
    "        mu, sigma = mu_0, sigma_0\n",
    "    else:\n",
    "        print('Wrong estimation method chosen!')\n",
    "        return()\n",
    "        \n",
    "    n_dev = np.round(0.05*n); z_i = (y_os - mu)/sigma\n",
    "    i = np.array(range(n)) + 1; p_i = (i - 0.5)/n\n",
    "\n",
    "    z_th = norm.ppf(p_i, 0, 1)\n",
    "    SE_z_th = (1/norm.pdf(z_th, 0, 1)) * np.sqrt((p_i * (1 - p_i)) / n)\n",
    "    CI_upper = z_th + 1.96 * SE_z_th; CI_lower = z_th - 1.96 * SE_z_th\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.plot(z_th, z_i, 'o', color='k', label='experimental data')\n",
    "    plt.plot(z_th, z_th, '--', color='r', label='normal line')\n",
    "    plt.plot(z_th, CI_upper, '--', color='b', label='95% CI')\n",
    "    plt.plot(z_th, CI_lower, '--', color='b')\n",
    "    plt.xlabel('Theoretical quantiles, $z_{(i)}$')\n",
    "    plt.ylabel('Sample quantiles, $z_i$')\n",
    "    plt.title('Q-Q plot (' + est + ') Data: ' + column, size = 10 )\n",
    "    plt.legend(loc='best'); plt.show();\n",
    "    print('Estimation method: ' + est)\n",
    "    print('n = {:d}, mu = {:.4g}, sigma = {:.4g}'.format(n, mu,sigma))\n",
    "    \n",
    "    # Expected number of deviations (95% confidence level):\n",
    "    n_dev = np.round(0.05*n)\n",
    "    \n",
    "    print('Expected number of data outside CI: {:.0f}'.format(n_dev))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "def choose_column(column):\n",
    "    y = df[column]\n",
    "    DS_Q_Q_Plot(y, est='robust', column=column)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "columns = df.columns.tolist()\n",
    "exclude = ['ZIPCODE', 'GENDER']\n",
    "y_columns = [c for c in columns if c not in exclude]\n",
    "\n",
    "widgets.interact(choose_column, column=widgets.Dropdown(\n",
    "    options=y_columns, description='Dataset:'));\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 33 data points out of more than 650 data fall outside of the confidence interval, but this is not necessarily important and we can assume that the data is normally distributed.\n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assume the data is stored in a pandas dataframe named \"df\"\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot SCOR_VAL and SCOR_NO_VAL\n",
    "male = df[df['GENDER'] == 'Male']\n",
    "female = df[df['GENDER'] == 'Female']\n",
    "ax1.scatter(male['SCOR_VAL'], male['LDI_SUM_T1'], c='blue', label='Male')\n",
    "ax1.scatter(female['SCOR_VAL'], female['LDI_SUM_T1'], c='red', label='Female')\n",
    "ax1.set_xlabel('SCOR_VAL')\n",
    "ax1.set_ylabel('LDI_SUM_T1')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot LTE_SUM_T1 and LTE_SUM_T2\n",
    "ax2.scatter(male['SCOR_VAL'], male['LTE_SUM_T1'], c='blue', label='Male')\n",
    "ax2.scatter(female['SCOR_VAL'], female['LTE_SUM_T1'], c='red', label='Female')\n",
    "ax2.set_xlabel('SCOR_VAL')\n",
    "ax2.set_ylabel('LTE_SUM_T1')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the data is stored in a pandas dataframe named \"df\"\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot SCOR_VAL and SCOR_NO_VAL\n",
    "male = df[df['GENDER'] == 1]\n",
    "female = df[df['GENDER'] == 2]\n",
    "ax1.scatter(male['MWK_VAL'], male['LTE_SUM_T1'], c='blue', label='Male')\n",
    "ax1.scatter(female['MWK_VAL'], female['LTE_SUM_T1'], c='red', label='Female')\n",
    "ax1.set_xlabel('MWK_VAL')\n",
    "ax1.set_ylabel('LTE_SUM_T1')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot LTE_SUM_T1 and LTE_SUM_T2\n",
    "ax2.scatter(male['MWK_NO_VAL'], male['LDI_SUM_T1'], c='blue', label='Male')\n",
    "ax2.scatter(female['MWK_NO_VAL'], female['LDI_SUM_T1'], c='red', label='Female')\n",
    "ax2.set_xlabel('MWK_NO_VAL')\n",
    "ax2.set_ylabel('LDI_SUM_T1')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body Mass Index\n",
    "BMI is a person’s weight in kilograms divided by the square of height in meters. A high BMI can indicate high body fatness.\n",
    "\n",
    "To calculate BMI, see the Adult BMI Calculator or determine BMI by finding your height and weight in this BMI Index Chart.\n",
    "\n",
    "If your BMI is less than 18.5, it falls within the **underweight** range.\n",
    "\n",
    "If your BMI is 18.5 to <25, it falls within the **healthy** weight range.\n",
    "\n",
    "If your BMI is 25.0 to <30, it falls within the **overweight** range.\n",
    "\n",
    "If your BMI is 30.0 or higher, it falls within the **obesity** range.\n",
    "\n",
    "\n",
    "So, we can make categorize the BMI data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi = df['BMI_T1']\n",
    "cond_list = [bmi < 18.5, bmi < 25, bmi < 30, bmi >= 30]\n",
    "choice_list = [\"Underweight\", \"Healthy\", \"Overweight\", \"Obese\"]\n",
    "\n",
    "df['BMI_LEV'] = np.select(cond_list, choice_list)\n",
    "df['BMI_LEV'] = df['BMI_LEV'].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assume the data is stored in a pandas dataframe named \"df\"\n",
    "\n",
    "# Map the \"BMI level\" column to circle size values\n",
    "\n",
    "\n",
    "\n",
    "# Assume the data is stored in a pandas dataframe named \"df\"\n",
    "\n",
    "size_mapping = {\"Underweight\": 10, \"Healthy\": 20, \"Overweight\": 100, \"Obese\": 150}\n",
    "df['size'] = df['BMI_LEV'].map(size_mapping)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Create custom markers for each size\n",
    "markers = []\n",
    "sizes = list(size_mapping.values())\n",
    "for size in sizes:\n",
    "    marker = plt.scatter([],[], s=size, c='gray', alpha=0.5)\n",
    "    markers.append(marker)\n",
    "\n",
    "# Plot SCOR_VAL and SCOR_NO_VAL\n",
    "male = df[df['GENDER'] == 'Male']\n",
    "female = df[df['GENDER'] == 'Female']\n",
    "ax1.scatter(male['SCOR_VAL'], male['LDI_SUM_T1'], label='Male', s=male['size'], alpha=0.4, color='dodgerblue')\n",
    "ax1.scatter(female['SCOR_VAL'], female['LDI_SUM_T1'], label='Female', s=female['size'],  alpha=0.4, color='hotpink')\n",
    "ax1.set_xlabel('SCOR_VAL')\n",
    "ax1.set_ylabel('LDI_SUM_T1')\n",
    "\n",
    "# Add the size information to the legend\n",
    "labels = list(size_mapping.keys())\n",
    "legend1 = ax1.legend(markers, labels, loc='best', title='BMI level')\n",
    "ax1.add_artist(legend1)\n",
    "\n",
    "# Add the gender information to the legend\n",
    "legend2 = ax1.legend(loc='upper left', title='Gender')\n",
    "\n",
    "# Plot LTE_SUM_T1 and LTE_SUM_T2\n",
    "ax2.scatter(male['SCOR_VAL'], male['LTE_SUM_T1'], label='Male', s=male['size'], alpha=0.4, color='dodgerblue')\n",
    "ax2.scatter(female['SCOR_VAL'], female['LTE_SUM_T1'], label='Female', s=female['size'],  alpha=0.4, color='hotpink')\n",
    "ax2.set_xlabel('SCOR_VAL')\n",
    "ax2.set_ylabel('LTE_SUM_T1')\n",
    "\n",
    "# Add the size information to the legend\n",
    "legend1 = ax2.legend(markers, labels, loc='best', title='BMI level')\n",
    "# ax2.add_artist(legend1)\n",
    "\n",
    "# Add the gender information to the legend\n",
    "legend2 = ax2.legend(loc='upper left', title='Gender')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress Index\n",
    "The List of Threatening Experiences (LTE) is a reliable and valid measure of stress in mental health, and the strength of its association with mental disorders depends on the method used to quantify the LTE scores.\n",
    "\n",
    "The validated List of Threatening Events (LTE) and Long-term Difficulties Inventory (LDI) were utilized in the past to measure stress, with higher scores indicating higher levels of stress. The LTE consists of 12 major categories of stressful life events, with a range sum score of 0 to 12, while the LDI measures exposure to long-term difficulties in 12 life domains, with a range sum score of 0 to 24.\n",
    "\n",
    "The total scores were divided into various categories, for example:\n",
    "\n",
    "LTE: 0, 1, 2, and ≥3\n",
    "LDI: 0, 1-2, 3-4, and ≥5\n",
    "\n",
    "In the study, items were scored on a two-point Likert scale.\n",
    "\n",
    "    Short-term stress (LTE): Mild (≤1.5), Severe (>1.5)\n",
    "    Long-term stress (LDI): Mild (≤2.5), Severe (>2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LTE_LEV'] = ''\n",
    "lte = df['LTE_SUM_T1']\n",
    "cond_list = [lte <= 1.50, lte > 1.50]\n",
    "choice_list = [\"Mild\", \"Severe\"]\n",
    "df['LTE_LEV'] = np.select(cond_list, choice_list)\n",
    "df['LTE_LEV'] = df['LTE_LEV'].astype(\"category\")\n",
    "\n",
    "df['LDI_LEV'] = ''\n",
    "ldi = df['LDI_SUM_T1']\n",
    "cond_list = [ldi <= 2.50, ldi > 2.50]\n",
    "choice_list = [\"Mild\", \"Severe\"]\n",
    "df['LDI_LEV'] = np.select(cond_list, choice_list)\n",
    "df['LDI_LEV'] = df['LDI_LEV'].astype(\"category\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into male and female participants\n",
    "male = df[df['GENDER'] == 1]\n",
    "female = df[df['GENDER'] == 2]\n",
    "\n",
    "# Plot the stress level (LDI_SUM_T1) against age (AGE_CAT) for male and female participants\n",
    "plt.scatter(male['AGE_T1'], male['MWK_VAL'], label='Male', alpha=0.4, color='dodgerblue')\n",
    "plt.scatter(female['AGE_T1'], female['MWK_VAL'], label='Female', alpha=0.4, color='hotpink')\n",
    "# Set the x and y axis limits based on the minimum and maximum values of the data\n",
    "plt.xlim(df['AGE_T1'].min() - 10, df['AGE_T1'].max() + 10)\n",
    "plt.ylim(df['MWK_VAL'].min() - 100, df['MWK_VAL'].max() + 100)\n",
    "\n",
    "# Add labels and a legend to the plot\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Physical Activity (MWK_VAL)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assume the data is stored in a pandas dataframe named \"df\"\n",
    "\n",
    "# Map the \"BMI level\" column to circle size values\n",
    "\n",
    "\n",
    "\n",
    "# Assume the data is stored in a pandas dataframe named \"df\"\n",
    "\n",
    "size_mapping = {\"Underweight\": 10, \"Healthy\": 20, \"Overweight\": 100, \"Obese\": 150}\n",
    "df['size'] = df['BMI_LEV'].map(size_mapping)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Create custom markers for each size\n",
    "markers = []\n",
    "sizes = list(size_mapping.values())\n",
    "for size in sizes:\n",
    "    marker = plt.scatter([],[], s=size, c='gray', alpha=0.5)\n",
    "    markers.append(marker)\n",
    "\n",
    "# Plot SCOR_VAL and SCOR_NO_VAL\n",
    "male = df[df['GENDER'] == 'Male']\n",
    "female = df[df['GENDER'] == 'Female']\n",
    "ax1.scatter(male['SCOR_VAL'], male['LDI_SUM_T1'], label='Male', s=male['size'], alpha=0.4, color='dodgerblue')\n",
    "ax1.scatter(female['SCOR_VAL'], female['LDI_SUM_T1'], label='Female', s=female['size'],  alpha=0.4, color='hotpink')\n",
    "ax1.set_xlabel('SCOR_VAL')\n",
    "ax1.set_ylabel('LDI_SUM_T1')\n",
    "\n",
    "# Add the size information to the legend\n",
    "labels = list(size_mapping.keys())\n",
    "legend1 = ax1.legend(markers, labels, loc='best', title='BMI level')\n",
    "ax1.add_artist(legend1)\n",
    "\n",
    "# Add the gender information to the legend\n",
    "legend2 = ax1.legend(loc='upper left', title='Gender')\n",
    "\n",
    "# Plot LTE_SUM_T1 and LTE_SUM_T2\n",
    "ax2.scatter(male['SCOR_VAL'], male['LTE_SUM_T1'], label='Male', s=male['size'], alpha=0.4, color='dodgerblue')\n",
    "ax2.scatter(female['SCOR_VAL'], female['LTE_SUM_T1'], label='Female', s=female['size'],  alpha=0.4, color='hotpink')\n",
    "ax2.set_xlabel('SCOR_VAL')\n",
    "ax2.set_ylabel('LTE_SUM_T1')\n",
    "\n",
    "# Add the size information to the legend\n",
    "legend1 = ax2.legend(markers, labels, loc='best', title='BMI level')\n",
    "# ax2.add_artist(legend1)\n",
    "\n",
    "# Add the gender information to the legend\n",
    "legend2 = ax2.legend(loc='upper left', title='Gender')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into male and female participants\n",
    "male = df[df['GENDER'] == 1]\n",
    "female = df[df['GENDER'] == 2]\n",
    "\n",
    "# Plot the stress level (LDI_SUM_T1) against age (AGE_CAT) for male and female participants\n",
    "plt.scatter(male['AGE_T1'], male['LDI_SUM_T1'], label='Male', alpha=0.4, color='dodgerblue')\n",
    "plt.scatter(female['AGE_T1'], female['LDI_SUM_T1'], label='Female', alpha=0.4, color='hotpink')\n",
    "# Set the x and y axis limits based on the minimum and maximum values of the data\n",
    "plt.xlim(df['AGE_T1'].min() - 1, df['AGE_T1'].max() + 1)\n",
    "plt.ylim(df['LDI_SUM_T1'].min() - 1, df['LDI_SUM_T1'].max() + 1)\n",
    "\n",
    "# Add labels and a legend to the plot\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Stress Level (LDI_SUM_T1)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The easiest way for plotting boxplot.\n",
    "import seaborn as sns\n",
    "male = df[df['GENDER'] == 1]\n",
    "female = df[df['GENDER'] == 2]\n",
    "\n",
    "df['Stress level'] = 'Normal'\n",
    "df.loc[df['LDI_SUM_T1'] > 2, 'Stress level'] = 'Upper than normal'\n",
    "\n",
    "\n",
    "#sns.boxplot(x='Stress level', y='MWK_NO_VAL', hue = 'GENDER', data=df)\n",
    "sns.violinplot(x='Stress level', y='MWK_NO_VAL', hue = 'GENDER', palette=sns.color_palette(\"pastel\"), data = df, split = True)\n",
    "#order=['20 or less', '21 to 35', '36 to 50', '51 or more']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'LDI_SUM_T1'\n",
    "data_range = df[x].max() - df[x].min()\n",
    "print (df[x].max(),  df[x].min())\n",
    "print(data_range)\n",
    "df[x].median()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypothesis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "\n",
    "sns.boxplot(x='LDI_LEV', y='MWK_NO_VAL',palette='husl', hue = 'GENDER', data=df, ax=ax1)\n",
    "ax1.set_xlabel('long term Stress')\n",
    "ax1.set_ylabel('Minutes of weekly physical activity in leisure time')\n",
    "\n",
    "\n",
    "sns.boxplot(x='LDI_LEV', y='MWK_VAL', data=df, palette='husl', hue = 'GENDER', ax=ax2)\n",
    "ax2.set_xlabel('Short term Stress')\n",
    "ax2.set_ylabel('Minutes of weekly physical activity on high intensity level')\n",
    "\n",
    "sns.boxplot(x='LDI_LEV', y='SPORTS_T1', data=df, palette='husl', hue = 'GENDER', ax=ax3)\n",
    "ax3.set_xlabel('Short term Stress')\n",
    "ax3.set_ylabel('Minutes of weekly Sport')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "df['Stress level'] = 'Normal'\n",
    "df.loc[df['LDI_SUM_T1'] > 2.5, 'Stress level'] = 'Upper than normal'\n",
    "\n",
    "sns.boxplot(x='Stress level', y='SPORTS_T1', data=df, ax=ax1)\n",
    "ax1.set_xlabel('Stress level')\n",
    "ax1.set_ylabel('SPORTS_T1')\n",
    "\n",
    "sns.boxplot(x='Stress level', y='SCOR_VAL', data=df, palette='husl', ax=ax2)\n",
    "ax2.set_xlabel('Stress level')\n",
    "ax2.set_ylabel('SCOR_VAL')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_selector(plot_type):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    if plot_type == 'LTE_SUM_T1':\n",
    "        df['Stress level'] = 'Normal'\n",
    "        df.loc[df['LTE_SUM_T1'] > 1.5, 'Stress level'] = 'Upper than normal'\n",
    "        sns.boxplot(x='Stress level', y='SCOR_VAL', data=df,hue = 'GENDER',  palette='Set1',color='gray', ax=ax1)\n",
    "        sns.boxplot(x='Stress level', y='SCOR_NO_VAL', data=df,hue = 'GENDER',  palette='Set2',color='gray', ax=ax2)\n",
    "        ax1.set_xlabel('Stress level')\n",
    "        ax1.set_ylabel('SCOR_NO_VAL')\n",
    "        ax2.set_ylabel('SCOR_VAL')\n",
    "    elif plot_type == 'LDI_SUM_T1':\n",
    "        df['Stress level'] = 'Normal'\n",
    "        df.loc[df['LDI_SUM_T1'] > 2.5, 'Stress level'] = 'Upper than normal'\n",
    "        sns.boxplot(x='Stress level', y='SCOR_VAL', data=df, hue = 'GENDER', palette='Set1',color='gray', ax=ax1)\n",
    "        sns.boxplot(x='Stress level', y='SCOR_NO_VAL', data=df, hue = 'GENDER', palette='Set2',color='gray', ax=ax2)\n",
    "        ax2.set_xlabel('Stress level')\n",
    "        ax1.set_ylabel('SCOR_NO_VAL')\n",
    "        ax2.set_ylabel('SCOR_VAL')\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_select = widgets.Dropdown(\n",
    "    options=['LTE_SUM_T1', 'LDI_SUM_T1'],\n",
    "    value='LTE_SUM_T1',\n",
    "    description='Plot Type:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "widgets.interact(plot_selector, plot_type=plot_select)\n",
    "display()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pairwise Pearson's correlation coefficients between all variables. The correlation coefficients are then visualized as a heatmap.\n",
    "The purpose of this code is to visualize the relationships between variables in the dataframe in a quick and easy-to-understand way.\n",
    "\n",
    "In this heatmap, the closer the correlation coefficient is to 1, the stronger the positive linear relationship between two variables, and the closer the correlation coefficient is to -1, the stronger the negative linear relationship between two variables. A correlation coefficient of 0 indicates no linear relationship between two variables.\n",
    "In general, a correlation coefficient of 0.1 is considered a small correlation, a coefficient of 0.3 is considered a moderate correlation, and a coefficient of 0.5 or higher is considered a strong correlation. However, these cut-offs are not absolute and can vary based on the context of the data and the field of study.\n",
    "A negative sign indicates a negative linear relationship, meaning that as one variable increases, the other variable decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap=\"YlGnBu\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "The heatmap provides a visual representation of the correlation matrix of the variables in the dataset. From the heatmap, we can observe that the variable \"LTE\" (short-term stress) has a moderate positive correlation with \"LDI\" (long-term stress, r = 0.47) and a moderate positive correlation with \"BMI\" (body mass index, r = 0.23). These correlations suggest that individuals who experience more short-term stress tend to have higher levels of long-term stress and a higher body mass index.\n",
    "\n",
    "In addition, the heatmap also shows that the variable \"LDI\" (long-term stress) has a moderate negative correlation with \"Age\" (r = -0.47), a moderate negative correlation with \"MWK\" (minutes of physical activity in leisure time per week, r = -0.32), a moderate positive correlation with \"LTE\" (short-term stress, r = 0.47), a moderate negative correlation with \"BMI\" (r = -0.3), and a small positive correlation with \"Sport\" (minutes of sport per week, r = 0.24). These correlations suggest that individuals who experience more long-term stress tend to be younger, engage in less physical activity during leisure time, and have a lower body mass index, while also engaging in a slightly higher amount of sport activity.\n",
    "\n",
    "It is important to note that the correlations presented here are only indicative of linear relationships and do not necessarily imply causality. Further analysis,  may be necessary to determine the effect of the variables on each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For determining the impact of stress level (severe versus mild) on physical activity in individuals over a long-term period, we use the two-sample t-test for means, also known as the independent samples t-test. This test is used to compare the means of two independent groups and is commonly utilized when there is a need to determine if a significant difference exists between the means of the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DS_2sample_ttest_means(y1, y2, equal_var=False, alternative='two-sided', alpha=0.05):\n",
    "    \"\"\"\n",
    "    *\n",
    "    Function DS_2sample_ttest_means(y1, y2, equal_var=False, alternative='two-sided', alpha=0.05)\n",
    "    \n",
    "       This function performs a 2-sample (Welch's) t-test (Null Hypothesis Significance Test) \n",
    "       in the spirit of R, testing 2 averages with *unknown* standard deviation.\n",
    "       The function also evaluates the effect size (Cohen's d).\n",
    "       \n",
    "    Requires:          -\n",
    "       \n",
    "    Usage:             DS_2sample_ttest_means(y1, y2, \n",
    "                            alternative=['two-sided']/'less'/'greater',\n",
    "                            equal_var=[False]/True, alpha = 0.05)\n",
    "     \n",
    "                         alternative = 'two-sided' [default]  H1: mu_1 != mu_2\n",
    "                                       'less'                 H1: mu_1 < mu_2\n",
    "                                       'greater'              H1: mu_1 > mu_2\n",
    "                         equal_var = False                    perform Welch t-test\n",
    "                                     True                     perform 2-sample t-test\n",
    "                         alpha:   significance level of test [default: 0.05]\n",
    "     \n",
    "    Return:            t, p-value, t.crit.L, t.crit.R  [ + print interpretable output to stdout ]\n",
    "                       where t.crit.L and t.crit.R are the lower and upper critical values, \n",
    "                       t is the test statistic and p-value is the p-value of the test.     \n",
    "     \n",
    "    Author:            M.E.F. Apol\n",
    "    Date:              2022-01-28, rev. 2022_08_26\n",
    "    Validation:\n",
    "    \"\"\"\n",
    "    \n",
    "    from scipy.stats import ttest_ind\n",
    "    from scipy.stats import t as t_distr\n",
    "    import numpy as np\n",
    "    \n",
    "    t, p_samp = ttest_ind(y1, y2, equal_var = equal_var)\n",
    "    y_av_1 = np.mean(y1)\n",
    "    y_av_2 = np.mean(y2)\n",
    "    n_1 = len(y1)\n",
    "    n_2 = len(y2)\n",
    "    s2_1 = np.var(y1, ddof=1)\n",
    "    s2_2 = np.var(y2, ddof=1)\n",
    "    print(80*'-')\n",
    "    if equal_var == True:\n",
    "        print('2-sample t-test for 2 means:')\n",
    "        print('     assuming Normal(mu.1, sigma2) data for dataset 1')\n",
    "        print('     assuming Normal(mu.2, sigma2) data for dataset 2')\n",
    "        df = n_1 + n_2 - 2\n",
    "    else:\n",
    "        print('Welch t-test for 2 means:')\n",
    "        df = (s2_1/n_1 + s2_2/n_2)**2 / ( 1/(n_1-1)*(s2_1/n_1)**2 + 1/(n_2-1)*(s2_2/n_2)**2 )\n",
    "        print('     assuming Normal(mu.1, sigma2.1) data for dataset 1')\n",
    "        print('     assuming Normal(mu.2, sigma2.2) data for dataset 2')\n",
    "    print('y.av.1 = {:.3g}, y.av.2 = {:.3g}, s2.1 = {:.3g}, s2.2 = {:.3g}, n.1 = {:d}, n.2 = {:d}, alpha = {:.3g}'.format(y_av_1, y_av_2, s2_1, s2_2, n_1, n_2, alpha))\n",
    "    print('H0: mu.1  = mu.2')\n",
    "    if alternative == 'two-sided':\n",
    "        print('H1: mu.1 != mu.2')\n",
    "        p_value = p_samp\n",
    "        t_crit_L = t_distr.ppf(alpha/2, df)\n",
    "        t_crit_R = t_distr.ppf(1-alpha/2, df)      \n",
    "    elif alternative == 'less':\n",
    "        print('H1: mu.1  < mu.2')\n",
    "        if t <= 0:\n",
    "            p_value = p_samp/2\n",
    "        else:\n",
    "            p_value = 1 - p_samp/2\n",
    "        t_crit_L = t_distr.ppf(alpha, df)\n",
    "        t_crit_R = float('inf')\n",
    "    elif alternative == 'greater':\n",
    "        print('H1: mu.1  > mu.2')\n",
    "        if t >= 0:\n",
    "            p_value = p_samp/2\n",
    "        else:\n",
    "            p_value = 1 - p_samp/2\n",
    "        t_crit_L = float('-inf')\n",
    "        t_crit_R = t_distr.ppf(1-alpha, df)\n",
    "    else:\n",
    "        print('Wrong alternative hypothesis chosen!')\n",
    "        print(80*'-' + '\\n')\n",
    "        t, p_value, t_crit_L, t_crit_R = np.nan, np.nan, np.nan, np.nan\n",
    "        return(t, p_value, t_crit_L, t_crit_R)\n",
    "    \n",
    "    # Effect size (Cohen's d.av):\n",
    "    d_av = t * np.sqrt(1/n_1 + 1/n_2)\n",
    "    print('t = {:.4g}, p-value = {:.4g}, t.crit.L = {:.4g}, t.crit.R = {:.4g}, df = {:.4g}'.format(t, p_value, t_crit_L, t_crit_R, df))\n",
    "    print('Effect size: d.av = {:.3g}; benchmarks |d.av|: 0.2 = small, 0.5 = medium, 0.8 = large'.format(d_av))\n",
    "    print(80*'-' + '\\n')\n",
    "    return(t, p_value, t_crit_L, t_crit_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild_ldi = df[df[\"LDI_LEV\"] == 'Mild']\n",
    "df_severe_ldi = df[df[\"LDI_LEV\"] == 'Severe']\n",
    "y2 = df_mild_ldi[\"MWK_VAL\"]\n",
    "y1 = df_severe_ldi[\"MWK_VAL\"]\n",
    "DS_2sample_ttest_means(y1, y2, alternative='less')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**interpretation**\n",
    "\n",
    "The result of the Welch t-test suggests that there is a significant difference in the mean minutes of physical activity between individuals who have experienced severe stress and those who have faced mild stress in the long-term.\n",
    "\n",
    "The negative test statistic, t = -9.479, indicates that individuals with severe stress have a lower mean physical activity time compared to those with mild stress. This finding is supported by the p-value of 2.737e-20, which is less than the alpha level of 0.05, suggesting that the null hypothesis (H0: mu.1 = mu.2) can be rejected.\n",
    "\n",
    "In essence, the results of the test show that individuals with severe stress tend to have a lower mean physical activity time compared to those with mild stress in the long-term, and this difference is considered substantial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild_lte = df[df[\"LTE_LEV\"] == 'Mild']\n",
    "df_severe_lte = df[df[\"LTE_LEV\"] == 'Severe']\n",
    "y2 = df_mild_lte[\"MWK_VAL\"]\n",
    "y1 = df_severe_lte[\"MWK_VAL\"]\n",
    "DS_2sample_ttest_means(y1, y2, alternative='two-sided')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**interpretation**\n",
    "\n",
    "The p-value is 0.7744, indicating the likelihood of observing a t-statistic value as extreme as -0.2959, given that the null hypothesis is true. When the p-value is greater than the significance level (α = 0.05), it means that we fail to reject the null hypothesis, indicating that there is not enough evidence to suggest a difference in the means of physical activity time in individuals with short-term stress levels of either mild or severe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the shapefile into a GeoDataFrame\n",
    "gdf = gpd.read_file(\"C:\\zshahpouri\\data\\georef-netherlands-postcode-pc4.shp\")\n",
    "gdf = gdf.rename(columns = {'pc4_code':'ZIPCODE'})\n",
    "\n",
    "\n",
    "gdf['ZIPCODE'] = gdf['ZIPCODE'].astype(float)\n",
    "# Merge the data with the GeoDataFrame based on the city name\n",
    "merged_gdf = gdf.merge(df, left_on='ZIPCODE', right_on='ZIPCODE')\n",
    "\n",
    "# Plot the geo plot using the 'plot' method from GeoPandas\n",
    "merged_gdf.plot(column='SCOR_VAL', cmap='RdYlGn', legend=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load the shapefile into a GeoDataFrame\n",
    "gdf = gpd.read_file(\"C:\\zshahpouri\\data\\georef-netherlands-postcode-pc4.shp\")\n",
    "gdf = gdf.rename(columns = {'pc4_code':'ZIPCODE'})\n",
    "\n",
    "# Merge the data with the GeoDataFrame based on the city name\n",
    "merged_gdf = gdf.merge(df, left_on='ZIPCODE', right_on='ZIPCODE')\n",
    "\n",
    "# Create a map object centered on the Netherlands\n",
    "m = folium.Map(location=[52.3, 5.0], zoom_start=8)\n",
    "\n",
    "# Create a GeoJSON object from the merged GeoDataFrame\n",
    "geo_json = folium.GeoJson(\n",
    "    merged_gdf.to_json(),\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': '#00ff00',\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the GeoJSON object to the map\n",
    "geo_json.add_to(m)\n",
    "\n",
    "# Loop through the data points and add markers for each one\n",
    "for i, row in merged_gdf.iterrows():\n",
    "    folium.CircleMarker(location=[row['geometry'].y, row['geometry'].x],radius=5,color='red',fill=True,fill_color='red',opacity=0.7,popup=str(row['SCOR_VAL'])).add_to(m)\n",
    "\n",
    "            #Save the map\n",
    "m.save(\"map.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "108095e740c160118120ad5e22811b4aca9f414a6f3c55c969835bc2c10848d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
