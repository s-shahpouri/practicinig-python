{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 01 Assignment epileptic seizure\n",
    "\n",
    "As a Data Scientist you often have lots of data at our disposal. Unfortunately, data from real-life cases is often not nicely structured. We need to manipulate the unstructured and/or messy data into a structured or clean form. We need to drop rows and columns because they are not needed for the analysis or because we cannot use them in case of too many missing values. Maybe we need to relabel columns or reformat characters into numerical values. Or we need to combine data from several sources. Cleaning and manipulating data into a structured form is called data preparation. In this week we will practice the cleaning and manipulation of EEG data in order to conduct graphical and statistical analysis. We will use tools often used by data scientists; `python`, `numpy`, `pandas` and `bokeh`. You will learn about data wrangling with `pandas` and `numpy` and you will learn to visualize with `bokeh`. Concretely, you will preprocess the brain EEG data in an appropiate format in order to conduct statistical and visual analysis. \n",
    "\n",
    "Keywords: data loading, data inspection, data exploration, reshape data, data cleaning, timeseries, pandas, visualization, statistics, tidy table\n",
    "\n",
    "More to read: \n",
    "\n",
    "- Andrzejak RG, Lehnertz K, Rieke C, Mormann F, David P, Elger CE (2001) Indications of nonlinear deterministic and finite dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state, Phys. Rev. E, 64, 061907\n",
    "\n",
    "More about pandas and git:\n",
    "\n",
    "- https://fennaf.gitbook.io/bfvm22prog1/\n",
    "- https://opensourceuom.gitlab.io/blog/post_files/2022-02-23/git-essentials-cheatsheet.pdf\n",
    "- https://nbviewer.org/github/ageron/handson-ml/blob/master/tools_pandas.ipynb\n",
    "- https://github.com/fenna/BFVM22PROG1/blob/main/exercises/quiz_pandas.ipynb\n",
    "\n",
    "\n",
    "Learning objectives\n",
    "\n",
    "- Understand the concepts and benefits of vectorized manipulation \n",
    "- Understand the concepts of the visualization tool bokeh \n",
    "- Read, inspect, clean, and reshape a file into a tabular tidy format\n",
    "- Perform visual and statistical analysis for time series data\n",
    "- Maintain development environment \n",
    "- Apply coding standards and FAIR principles\n",
    "\n",
    "By the end of this week the student can:\n",
    "\n",
    "- load a tabular dataset and and rename the column names\n",
    "- split a text column into two columns in Pandas DataFrame\n",
    "- inspect the dataset for quality and metadata information\n",
    "- reshape the dataset into a format suitable for visual and statistical analysis\n",
    "- perform visual analysis\n",
    "- perform statistical analysis\n",
    "\n",
    "Please add your own topics you want to learn here: https://padlet.com/ffeenstra1/y97afib6ovx96lr9\n",
    "\n",
    "A final plot will look like this:\n",
    "\n",
    "<img src=\"../images/brain.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "The assignment consists of 6 parts:\n",
    "\n",
    "- [part 1: load the data](#0)\n",
    "     - [Exercise 1.1](#ex-11)\n",
    "- [part 2: prepare for inspection](#1)\n",
    "     - [Exercise 2.1](#ex-21)\n",
    "- [part 3: inspect the data](#2)\n",
    "     - [Exercise 3.1](#ex-31)\n",
    "- [part 4: reshape the data](#3)\n",
    "     - [Exercise 4.1](#ex-41)\n",
    "     - [Exercise 4.3](#ex-43)\n",
    "- [part 5: visualize the data](#4)\n",
    "     - [Exercise 5.1](#ex-51)\n",
    "- [part 6: statistical analysis](#5)\n",
    "     - [Exercise 6.1](#ex-61)\n",
    "\n",
    "\n",
    "Part 1 and 5 are mandatory, part 6 is optional (bonus)\n",
    "Mind you that you cannot copy code without referencing the code. If you copy code you need to be able to explain your code verbally and you will not get the full score. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "You will use a dataset called `eeg_data.csv`. This is a preprocessed dataset. The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for around 23 seconds. Each data point is the value of the EEG recording at a different point in time. There are in total 500 patients with each has 4097 datapoints.\n",
    "\n",
    "The originial data was shuffled into 23 chunks per patient, each chunk contains 178 data points. \n",
    "The first column is an identifier with the chunk number (X1 ..X23) and the Patient number (for example V1.791)\n",
    "The EEG recordings are X1, X2, ..., X178. The last column represents the label y {1,2,3,4,5}\n",
    "\n",
    "5 - eyes open, means when they were recording the EEG signal of the brain the patient had their eyes open\n",
    "\n",
    "4 - eyes closed, means when they were recording the EEG signal the patient had their eyes closed\n",
    "\n",
    "3 - Yes they identify where the region of the tumor was in the brain and recording the EEG activity from the healthy brain area\n",
    "\n",
    "2 - They recorder the EEG from the area where the tumor was located\n",
    "\n",
    "1 - Recording of seizure activity\n",
    "\n",
    "All subjects falling in classes 2, 3, 4, and 5 are subjects who did not have epileptic seizure. Only subjects in class 1 have epileptic seizure. \n",
    "\n",
    "Source: Andrzejak RG, Lehnertz K, Rieke C, Mormann F, David P, Elger CE (2001) Indications of nonlinear deterministic and finite dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state, Phys. Rev. E, 64, 061907\n",
    "\n",
    "\n",
    "Preferably we read the data not with a hard coded data path but using a config file. See https://fennaf.gitbook.io/bfvm22prog1/data-processing/configuration-files/yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to load in the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bokeh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbokeh\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m output_notebook\n\u001b[0;32m      4\u001b[0m output_notebook()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bokeh'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Part 1: Load the data\n",
    "\n",
    "Instructions: Load the data and rename the unnamed column containing the identifier with the chunck number and the patientID into the column `ID`\n",
    "\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<ul><li>pandas.read_csv() method can be used to read a csv file</li>\n",
    "    <li>pandas.DataFrame.head() method is often used to inspect the dataframe</li>\n",
    "    <li>pandas.DataFrame.rename() method can be used to rename columns</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-11'></a>\n",
    "### 1.1 Code your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv(\"eeg_data.csv\")\n",
    "df=df.rename(columns={\"Unnamed: 0\":\"ID\"})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not modify this cell, run cell to test your code\n",
    "try:\n",
    "    df.info()\n",
    "except:\n",
    "    print(\"df not properly loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected outcome: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 11500 entries, 0 to 11499\n",
    "    Columns: 180 entries, ID to y\n",
    "    dtypes: int64(179), object(1)\n",
    "    memory usage: 15.8+ MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset should have 11500 entries (500patients x 23 rows per patient) and 180 columns (178 recordings, an identifier and the class variable y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## Part 2: Prepare for inspection \n",
    "\n",
    "Although the number of records suggest that there should be 500 patients with 23 record each we would like to check this. Furthermore we do not know whether the y label is the same for each patient. We also do not know whether there are missing values. In order to answer the questions above it is more convient to split up the identifier containing a combination of chunck number and patient ID into two separate columns. After that we can do some inspections.\n",
    "\n",
    "Instructions: \n",
    "\n",
    "- change the `ID` column into two separate columns `idx` and `patient_id`\n",
    "- change the column `idx` into a number (you need to stripe the X first)\n",
    "- remove the `ID` column from the DataFrame\n",
    "\n",
    "\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<ul><li>pandas.DataFrame.str.split() method can be used to split</li>\n",
    "    <li>pandas.DataFrame.astype(int) method can be used to typecast to a number</li>\n",
    "    <li>pandas.DataFrame.drop() method can be used to drop a column</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "<a name='ex-21'></a>\n",
    "### 2.1 Code your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv(\"eeg_data.csv\")\n",
    "df=df.rename(columns={\"Unnamed: 0\":\"ID\"})\n",
    "df[[\"idx\",\"patient_id\"]]=df[\"ID\"].str.split(\".\",n=1, expand = True)\n",
    "\n",
    "df=df.drop(['ID'],axis=1)\n",
    "\n",
    "df[\"idx\"]=df[\"idx\"].str.strip('X')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not modify this cell, run cell to test your code\n",
    "try:\n",
    "    df.dtypes\n",
    "except:\n",
    "    print(\"df not properly loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### expected outcome:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X1             int64\n",
    "X2             int64\n",
    "X3             int64\n",
    "X4             int64\n",
    "X5             int64\n",
    "               ...  \n",
    "X177           int64\n",
    "X178           int64\n",
    "y              int64\n",
    "idx            int64\n",
    "patient_id    object\n",
    "Length: 181, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## Part 3: Inspect the data\n",
    "\n",
    "Now that we prepared the data we are going to inspect the data to get more familiar with the data. You are required to do the following\n",
    "\n",
    "- inspect how many patients are in the dataset (should be 500 different)\n",
    "- inspect if patient V1.924 has 23 records\n",
    "- check if a patient has more than 1 Y value\n",
    "- check for how many patients are there per level\n",
    "- check if there are missing values\n",
    "\n",
    "The code for the inspection of the chunk numbers is given.\n",
    "\n",
    "\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<ul><li>pandas.DataFrame.groupby()</li>\n",
    "    <li>(df[df['columnname'] == value])</li>\n",
    "    <li>if you sum the expression ['y'].min() == ['y'].max() when grouped by patient it should return 500</li>\n",
    "</ul>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-31'></a>\n",
    "### 3.1 Code your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should have 23 chunck numbers\n",
    "len(pd.DataFrame(df.groupby('idx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv(\"eeg_data.csv\")\n",
    "df=df.rename(columns={\"Unnamed: 0\":\"ID\"})\n",
    "df[[\"idx\",\"patient_id\"]]=df[\"ID\"].str.split(\".\",n=1, expand = True)\n",
    "df=df.drop(['ID'],axis=1)\n",
    "df[\"idx\"]=df[\"idx\"].str.strip('X')\n",
    "\n",
    "print(len(pd.DataFrame(df.groupby('patient_id'))))\n",
    "print(len(df.loc[df['patient_id'] == \"V1.942\"]))\n",
    "\n",
    "if len(pd.DataFrame(df.groupby('patient_id')))==len(pd.DataFrame(df.groupby(['patient_id','y']))):\n",
    "    print (\"There is no patient who has more than 1 Y valuea\")\n",
    "else:\n",
    "     print (\"there is at least  one patient who has more than 1 Y valuea \") \n",
    "\n",
    "if df.isna().sum().sum()==0:\n",
    "    print (\"There is no missing value\")\n",
    "else:\n",
    "     print (f\"There is {df.isna().sum().sum()} missing value\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## Part 4: Reshape the data\n",
    "\n",
    "We would like to plot the patient data. Therefore we would need to reshape the data. For plotting purpose the data of the 23 chunks need to be ordered by patient and chunk number first. And then we need to get the X1..X178 data (a matrix with shape 23, 178) to be reshaped to one array of 178 * 23 = 4094 datapoints. (shape 1, 4094). The 4094 datapoint array is the EEG signal data of a particular patient to be plotted on the y-axis. On the x-axis we simply can create a sequence from 1 to 4094. \n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- set the index to `patient_id` and `idx`\n",
    "- sort the index\n",
    "- create a timesequence from 1 to 4094\n",
    "- finish the code to select a patient\n",
    "- finish the code to get the data of a patient and reshape it into an one dimensional array\n",
    "\n",
    "\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<ul><li>df.set_index</li>\n",
    "    <li>df.sort_index</li>\n",
    "    <li>use np.arange to create the sequence and use tolist to transfer it to a list</li>\n",
    "    <li>check pandas.DataFrame.iloc and slicing options for selecting a subset of the data</li>\n",
    "    <li>with numpy.reshape you can reshape a matrix</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "<a name='ex-41'></a>\n",
    "### 4.1 Code your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['patient_id','idx'])\n",
    "df=df.sort_index(ascending=True)\n",
    "\n",
    "print('DataFrame after sorting\\n')\n",
    "print(df)\n",
    "print('\\n------------------')\n",
    "\n",
    "timeseq = []\n",
    "timeseq=np.arange(1,4095)\n",
    "\n",
    "df_reshape=np.reshape(df.iloc[0:23].to_numpy(), 4117)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check outcome df and timeseq, do not modify this cell, run to test\n",
    "print(df_reshape.head(2))\n",
    "print(f'the length of timeseq [{np.array(timeseq).min()}..{np.array(timeseq).max()}] is {len(timeseq)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### expected outcome:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "                    X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X170  X171  \\\n",
    "patient_id idx                                           ...               \n",
    "V1         1    12  22  35  45  69  74  79  78  66   43  ...   -18   -32   \n",
    "           2   -41 -50 -53 -49 -35 -28 -15  -2  14   18  ...    34    22   \n",
    "\n",
    "                X172  X173  X174  X175  X176  X177  X178  y  \n",
    "patient_id idx                                               \n",
    "V1         1     -47   -53   -48   -40   -17   -23   -32  5  \n",
    "           2       4   -18   -31   -27   -26   -21   -30  5  \n",
    "\n",
    "[2 rows x 179 columns]\n",
    "the length of timeseq [1..4094] is 4094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now that we reorganized the patients we could use the new dataframe to select a patient, load the values in an numpy matrix and reshape that to a one dimensional array. To do such complete the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-43'></a>\n",
    "### 4.3 Code your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data of one patient\n",
    "def get_patient(df, patient):\n",
    "    \n",
    "    dfpat = df.loc[patient]\n",
    "    dfpat=dfpat.set_index(['y'])\n",
    "    return dfpat.sort_index()\n",
    "\n",
    "\n",
    "#fetch the values part and put in numpy array\n",
    "def get_values(df):\n",
    "    X = np.array(df) \n",
    "    n = int(len(df) / 23)\n",
    "    X = X.reshape(n, 4094)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.4 Test your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check outcome of array, do not modify this cell, run to test\n",
    "test_patient = get_values(get_patient(df,'V1.334'))[0]\n",
    "print(f'the length of patient V1.334 array {test_patient} = {len(test_patient)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expected outcome"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "the length of patient V1.334 array [ -18  -55 -126 ... -210 -222 -224] = 4094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## Part 5: Plot the data\n",
    "\n",
    "In this part we will first select some patients per class level in the function `get_data(level)`. Then we are going to plot two plots per level using bokeh. Your job is to finish the code of the bokeh plot. For each patient eeg signal should be plotted on the y-axis given the timesequence on the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to select some patients per level, do not modify this cell, run this cell\n",
    "#it is allowed though to add some print statements in order to understand what is happening\n",
    "def get_data(level):\n",
    "    df_level = df[df['y']==level]\n",
    "    s = df_level.index.unique().tolist()\n",
    "    patients = np.array(sorted(set([x[0] for x in s]))).tolist()\n",
    "    return list(patients)[3:5]\n",
    "\n",
    "p1 = get_data(1)\n",
    "p2 = get_data(2)\n",
    "p3 = get_data(3)\n",
    "p4 = get_data(4)\n",
    "p5 = get_data(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-51'></a>\n",
    "### 5.1 Code your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "def make_plot(title, y, pat_values, timeseq, color):\n",
    "    p = figure(title=title, background_fill_color=\"#fafafa\")\n",
    "    p.y_range=Range1d(-1500, 1500)\n",
    "    \n",
    "    ###########################################\n",
    "    p.line(0,0, color=color) # CHANGE THIS LINE\n",
    "    ###########################################\n",
    "\n",
    "    p.xaxis.axis_label = 'time'\n",
    "    p.yaxis.axis_label = 'signal'\n",
    "    p.grid.grid_line_color=\"white\"\n",
    "    return p\n",
    "\n",
    "\n",
    "def make_plot_array(g, pa, y):\n",
    "    d = {1:'seizure', 2:'tumor location', 3:'non-tumor location', 4:'eyes closed', 5:'eyes open'}\n",
    "    for i in pa:\n",
    "        v = get_values(get_patient(df,i))[0]\n",
    "        p = make_plot(title = f'brain EEG for patient {i} {d[y]}', y=y, pat_values=v, timeseq=timeseq, color='black')\n",
    "        g.append(p)\n",
    "    return g\n",
    "\n",
    "g = []\n",
    "g = make_plot_array(g, p1, 1)\n",
    "g = make_plot_array(g, p2, 2)\n",
    "g = make_plot_array(g, p3, 3)\n",
    "g = make_plot_array(g, p4, 4)\n",
    "g = make_plot_array(g, p5, 5)\n",
    "    \n",
    "show(gridplot(g, ncols=2, plot_width=450, plot_height=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## Part 6: Statistical analysis (bonus points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphical analysis is seems that there is significant difference between level 1 and the other levels. We can use `pandas.DataFrame.melt` to prepare the data for statistical analysis. Your job is to give statistical evidence of a significant difference see also [gitbook example](https://fennaf.gitbook.io/bfvm19prog1/data-wrangling/reshape-with-melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-61'></a>\n",
    "### 6.1 Code your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "import seaborn as sns\n",
    "dfm = df.melt(id_vars=['y'])\n",
    "sns.violinplot(x=dfm.y, y=dfm.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "108095e740c160118120ad5e22811b4aca9f414a6f3c55c969835bc2c10848d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
